@article{Ahlberg2001,
	abstract = {During the last decade, CANDIDE has been a popular face model in many research labs around the world. One reason has been that it is a very simple model, another that it is publically available. There are, however, drawbacks with the model, mostly due to its simplicity. Also, the emergence of the MPEG-4 standard for face animation has actualized the need of an update, making the model compatible with the facial animation and definition parameters ( FAPs and FDPs) defined in MPEG-4. This report documents an updated version of CANDIDE , fulfilling the demands set by MPEG-4 and being somewhat less crude. The relation between the CANDIDE entities (vertices, Action Units) and the MPEG-4 parameters are available in tables in the appendices.},
	author = {Ahlberg, J{\"{o}}rgen},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/LiTH-ISY-R-2326.pdf:pdf},
	isbn = {LiTH-ISY-R-2326},
	journal = {LiTH-ISY-R-2326},
	pages = {1--16},
	title = {{Candide-3. An updated parameterised face}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.5603},
	volume = {1},
	year = {2001}
}
@article{Aly2016,
	author = {Aly, Sherin and Abbott, A. Lynn and Torki, Marwan},
	doi = {10.1109/WACV.2016.7477577},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/07477577.pdf:pdf},
	isbn = {9781509006410},
	journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
	title = {{A multi-modal feature fusion framework for kinect-based facial expression recognition using Dual Kernel Discriminant Analysis (DKDA)}},
	year = {2016}
}
@article{Qayyum2017,
	author = {Qayyum, Huma and Majid, Muhammad and Anwar, Syed Muhammad and Khan, Bilal},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/9854050.pdf:pdf},
	number = {1},
	title = {{Transform Features}},
	volume = {2017},
	year = {2017}
}
@article{Liu2016,
	author = {Liu, Shuming and Chen, Xiaopeng and Fan, Di and Platform, A Hardware},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/07558813.pdf:pdf},
	isbn = {9781509023967},
	number = {2},
	pages = {1661--1666},
	title = {{3D Smiling Facial Expression Recognition Based on SVM}},
	year = {2016}
}
@article{Wei2016,
	author = {Wei, Wei and Jia, Qingxuan and Chen, Gang},
	doi = {10.1109/ICIEA.2016.7603570},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/07603570.pdf:pdf},
	isbn = {9781467386449},
	keywords = {face tracking,ffps,kinect,rgb-d database},
	pages = {161--165},
	title = {{Real-time Facial Expression Recognition for Affective Computing Based on Kinect}},
	year = {2016}
}
@article{Kalliatakis2017,
	abstract = {Despite significant recent advances in the field of head pose estimation and facial expression recognition, raising the cognitive level when analysing human activity presents serious challenges to current concepts. Motivated by the need of generating comprehensible visual representations from different sets of data, we introduce a system capable of monitoring human activity through head pose and facial expression changes, utilising an affordable 3D sensing technology (Microsoft Kinect sensor). An approach build on discriminative random regression forests was selected in order to rapidly and accurately estimate head pose changes in unconstrained environment. In order to complete the secondary process of recognising four universal dominant facial expressions (happiness, anger, sadness and surprise), emotion recognition via facial expressions (ERFE) was adopted. After that, a lightweight data exchange format (JavaScript Object Notation-JSON) is employed, in order to manipulate the data extracted from the two aforementioned settings. Such mechanism can yield a platform for objective and effortless assessment of human activity within the context of serious gaming and human-computer interaction.},
	archivePrefix = {arXiv},
	arxivId = {1703.03949},
	author = {Kalliatakis, Grigorios and Vidakis, Nikolaos and Triantafyllidis, Georgios},
	doi = {10.1109/CEEC.2016.7835887},
	eprint = {1703.03949},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/Web-based Visualisation of Head Pose and Facial Expressions Changes Monitoring Human Activity Using Depth Data.pdf:pdf},
	number = {September},
	title = {{Web-based visualisation of head pose and facial expressions changes: monitoring human activity using depth data}},
	url = {http://arxiv.org/abs/1703.03949{\%}0Ahttp://dx.doi.org/10.1109/CEEC.2016.7835887},
	year = {2017}
}
@article{Essa1997,
	abstract = {We describe a computer vision system for observing facial motion by using an optimal estimation optical flow method coupled with geometric, physical and motion-based dynamic models describing the facial structure. Our method produces a reliable parametric representation of the face's independent muscle action groups, as well as an accurate estimate of facial motion. Previous efforts at analysis of facial expression have been based on the facial action coding system (FACS), a representation developed in order to allow human psychologists to code expression from static pictures. To avoid use of this heuristic coding scheme, we have used our computer vision system to probabilistically characterize facial motion and muscle activation in an experimental population, thus deriving a new, more accurate, representation of human facial expressions that we call FACS+. Finally, we show how this method can be used for coding, analysis, interpretation, and recognition of facial expressions},
	author = {Essa, Irfan A. and Pentland, Alex P.},
	doi = {10.1109/34.598232},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/00598232.pdf:pdf},
	isbn = {0162-8828 VO - 19},
	issn = {01628828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Emotion recognition,Expression recognition,Face processing,Facial analysis,Facial expression analysis,Motion analysis,Perception of action,Vision-based HCI},
	number = {7},
	pages = {757--763},
	pmid = {12780641},
	title = {{Coding, analysis, interpretation, and recognition of facial expressions}},
	volume = {19},
	year = {1997}
}
@article{Lopes2017,
	abstract = {Facial expression recognition has been an active research area in the past 10 years, with growing application areas including avatar animation, neuromarketing and sociable robots. The recognition of facial expressions is not an easy problem for machine learning methods, since people can vary significantly in the way they show their expressions. Even images of the same person in the same facial expression can vary in brightness, background and pose, and these variations are emphasized if considering different subjects (because of variations in shape, ethnicity among others). Although facial expression recognition is very studied in the literature, few works perform fair evaluation avoiding mixing subjects while training and testing the proposed algorithms. Hence, facial expression recognition is still a challenging problem in computer vision. In this work, we propose a simple solution for facial expression recognition that uses a combination of Convolutional Neural Network and specific image pre-processing steps. Convolutional Neural Networks achieve better accuracy with big data. However, there are no publicly available datasets with sufficient data for facial expression recognition with deep architectures. Therefore, to tackle the problem, we apply some pre-processing techniques to extract only expression specific features from a face image and explore the presentation order of the samples during training. The experiments employed to evaluate our technique were carried out using three largely used public databases (CK+, JAFFE and BU-3DFE). A study of the impact of each image pre-processing operation in the accuracy rate is presented. The proposed method: achieves competitive results when compared with other facial expression recognition methods ??? 96.76{\%} of accuracy in the CK+ database ??? it is fast to train, and it allows for real time facial expression recognition with standard computers.},
	author = {Lopes, Andr?? Teixeira and de Aguiar, Edilson and {De Souza}, Alberto F. and Oliveira-Santos, Thiago},
	doi = {10.1016/j.patcog.2016.07.026},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/1-s2.0-S0031320316301753-main.pdf:pdf},
	issn = {00313203},
	journal = {Pattern Recognition},
	keywords = {Computer vision,Convolutional Neural Networks,Expression specific features,Facial expression recognition,Machine learning},
	pages = {610--628},
	publisher = {Elsevier},
	title = {{Facial expression recognition with Convolutional Neural Networks: Coping with few data and the training sample order}},
	url = {http://dx.doi.org/10.1016/j.patcog.2016.07.026},
	volume = {61},
	year = {2017}
}
@article{HuangC.&Huang1997,
	author = {{Huang, C. {\&} Huang}, Y. and {Huang, C. {\&} Huang}, Y.},
	doi = {10.1006/jvci.1997.0359},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/1-s2.0-S104732039790359X-main.pdf:pdf},
	issn = {10473203},
	journal = {Journal of Visual Communication and Image Representation},
	month = {sep},
	number = {3},
	pages = {278--290},
	title = {{Facial Expression Recognition Using Model-Based Feature Extraction and Action Parameters Classification}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S104732039790359X},
	volume = {8},
	year = {1997}
}
@article{Tian2001,
	author = {Tian, Y.-I. and Kanade, T. and Cohn, J.F.},
	doi = {10.1109/34.908962},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/00908962.pdf:pdf},
	issn = {01628828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	number = {2},
	pages = {97--115},
	title = {{Recognizing action units for facial expression analysis}},
	url = {http://ieeexplore.ieee.org/document/908962/},
	volume = {23},
	year = {2001}
}
@article{Lien1998,
	author = {Lien, James J. and Cohn, Jeffrey F. and Kanade, Takeo and Li, Ching Chung},
	doi = {10.1109/AFGR.1998.670980},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lien et al. - 1998 - Automated facial expression recognition based on FACS action units.pdf:pdf},
	isbn = {0818683449},
	journal = {Proceedings - 3rd IEEE International Conference on Automatic Face and Gesture Recognition, FG 1998},
	pages = {390--395},
	title = {{Automated facial expression recognition based on FACS action units}},
	year = {1998}
}
@inproceedings{Lien1998a,
	author = {Lien, James J. and Cohn, Jeffrey F. and Kanade, Takeo and Li, Ching Chung},
	booktitle = {Proceedings - 3rd IEEE International Conference on Automatic Face and Gesture Recognition, FG 1998},
	doi = {10.1109/AFGR.1998.670980},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lien et al. - 1998 - Automated facial expression recognition based on FACS action units.pdf:pdf},
	isbn = {0818683449},
	pages = {390--395},
	publisher = {IEEE Comput. Soc},
	title = {{Automated facial expression recognition based on FACS action units}},
	url = {http://ieeexplore.ieee.org/document/670980/},
	year = {1998}
}
@book{Lim2008,
	author = {Lim, Youn-kyung},
	booktitle = {Affect and Emotion in HCI, LNCS},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim - 2008 - Emotional Experience and Interaction Design.pdf:pdf},
	isbn = {9783540850984},
	pages = {116--129},
	title = {{Emotional Experience and Interaction Design}},
	url = {http://www.ulb.tu-darmstadt.de/tocs/59142804.pdf},
	year = {2008}
}
@article{Busso2004,
	author = {Busso, Carlos and Deng, Zhigang and Yildirim, Serdar and Bulut, Murtaza and Lee, Chul Min and Kazemzadeh, Abe and Lee, Sungbok and Neumann, Ulrich and Narayanan, Shrikanth S},
	doi = {10.1145/1027933.1027968},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Busso et al. - 2004 - Analysis of emotion recognition using facial expressions, speech and multimodal information.pdf:pdf},
	isbn = {1-58113-995-0},
	issn = {1581139543},
	journal = {Proceedings of the International Conference on Multimodal Interfaces},
	keywords = {PCA,SVC,affective states,decision level fusion,emotion recognition,feature level fusion,human-computer interaction (HCI),speech,vision},
	pages = {205--211},
	title = {{Analysis of emotion recognition using facial expressions, speech and multimodal information}},
	year = {2004}
}
@book{Books2007,
	abstract = {Most organizations use performance appraisal system to evaluate the effectiveness and efficiency of their employees. In evaluating staff performance, it usually involves awarding numerical values or linguistic labels to their performance. These values and labels are used to represent each staffs achievement by reasoning incorporated in the arithmetical or statistical methods. However, the staff performance appraisal may involve judgments which are based on imprecise data especially when human (the superior) tries to interpret another human (his/her subordinate) performance. Thus, the scores awarded by the appraiser are only approximations. From fuzzy logic perspective, the performance of the appraisee involves the measurement of his/her ability, competence and skills, which are actually fuzzy concepts that can be captured in fuzzy terms. Accordingly, fuzzy approach can be used to handle these imprecision and uncertainty information. Therefore, the performance appraisal system can be examined using Fuzzy Logic Approach and this was carried out in the study. The study utilized hierarchical fuzzy inference approach since performance evaluation comprises of four criteria; namely work achievement, skill knowledge, personal quality, and community services. The output of the study provides the ranking for staff performance. From this study, it is expected that reasoning based on fuzzy models will provide an alternative way in handling various kinds of imprecise data, which often reflected in the way people think and make judgments.},
	author = {Books, Free},
	booktitle = {Artificial Intelligence},
	doi = {10.1007/978-0-387-74161-1},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Books - 2007 - Artificial Intelligence and Innovations 2007 from Theory to Applications.pdf:pdf},
	isbn = {9780387741604},
	issn = {15715736},
	pages = {195--203},
	title = {{Artificial Intelligence and Innovations 2007: from Theory to Applications}},
	url = {http://scholar.google.com/scholar?hl=en{\&}{\#}38;btnG=Search{\&}{\#}38;q=intitle:ARTIFICIAL+INTELLIGENCE+AND+INNOVATIONS+2007:+FROM+THEORY+TO+APPLICATIONS{\#}1},
	volume = {247},
	year = {2007}
}
@article{Fasel2003,
	abstract = {Over the last decade, automatic facial expression analysis has become an active research area that finds potential applications in areas such as more engaging human-computer interfaces, talking heads, image retrieval and human emotion analysis. Facial expressions reflect not only emotions, but other mental activities, social interaction and physiological signals. In this survey, we introduce the most prominent automatic facial expression analysis methods and systems presented in the literature. Facial motion and deformation extraction approaches as well as classification methods are discussed with respect to issues such as face normalization, facial expression dynamics and facial expression intensity, but also with regard to their robustness towards environmental changes. ?? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
	author = {Fasel, B. and Luettin, Juergen},
	doi = {10.1016/S0031-3203(02)00052-3},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fasel, Luettin - 2003 - Automatic facial expression analysis A survey.pdf:pdf},
	isbn = {0031-3203},
	issn = {00313203},
	journal = {Pattern Recognition},
	keywords = {Affect recognition,Emotion recognition,FACS,Facial expression interpretation,Facial expression recognition},
	number = {1},
	pages = {259--275},
	title = {{Automatic facial expression analysis: A survey}},
	volume = {36},
	year = {2003}
}
@article{Darwin1872,
	abstract = {"Even cows, when they frisk about from pleasure, throw up their tails in aridiculous fashion." So writes Charles Darwin in his magnum opus on how humansand animals display such emotions as fear, anger, disdain, and pleasure; it iswork that has in most respects been sustained by later scientific research.First published in 1872, Darwin's greatest work was never issued in quite theshape its author intended: bits and pieces were left out of subsequentprintings, most of them released after Darwin's death, and later editors madeadditions to suit the intellectual fashion of their times. This definitiveedition, heavily annotated, brings us the book that Darwin would have wanted,and it is essential to any naturalist's library.},
	author = {Darwin, Charles},
	doi = {10.1097/00000441-195610000-00024},
	file = {:C$\backslash$:/Users/Andre Luiz/Downloads/Documents/Darwin{\_}1872.pdf:pdf},
	isbn = {0195158067},
	issn = {0002-9629},
	journal = {The American Journal of the Medical Sciences},
	number = {4},
	pages = {477},
	pmid = {19244859},
	title = {{The expression of the emotions in man and animals}},
	volume = {232},
	year = {1872}
}
@article{Cowie2001,
	abstract = {Two channels have been distinguished in human interaction: one transmits explicit messages, which may be about anything or nothing; the other transmits implicit messages about the speakers themselves. Both linguistics and technology have invested enormous efforts in understanding the first, explicit channel, but the second is not as well understood. Understanding the other party's emotions is one of the key tasks associated with the second, implicit channel. To tackle that task, signal processing and analysis techniques have to be developed, while, at the same time, consolidating psychological and linguistic analyses of emotion. This article examines basic issues in those areas. It is motivated by the PKYSTA project, in which we aim to develop a hybrid system capable of using information from faces and voices to recognize people's emotions},
	author = {Cowie, R and Douglas-Cowie, E and Tsapatsoulis, N and Votsis, G and Kollias, S and Fellenz, W and Taylor, J G},
	doi = {10.1109/79.911197},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cowie et al. - 2001 - Emotion recognition in human-computer interaction.pdf:pdf},
	isbn = {1053-5888},
	issn = {1053-5888},
	journal = {Signal Processing Magazine, IEEE},
	keywords = {PKYSTA project,emotion recognition,faces,human-com},
	number = {1},
	pages = {32--80},
	pmid = {15921887},
	title = {{Emotion recognition in human-computer interaction}},
	volume = {18},
	year = {2001}
}
@article{Cohn2007,
	abstract = {Many people believe that emotions and subjective feelings are one and the same and that a goal of human-centered computing is emotion recognition. The first belief is outdated; the second mistaken. For human- centered computing to succeed, a different way of thinking is needed. Emotions are species-typical patterns that evolved because of their value in addressing fundamental life tasks. Emotions consist of multiple components, of which subjective feelings may be one. They are not directly observable, but inferred from expressive behavior, self-report, physiological indicators, and context. I focus on expressive facial behavior because of its coherence with other indicators and research. Among the topics included are measurement, timing, individual differences, dyadic interaction, and inference. I propose that design and implementation of perceptual user interfaces may be better informed by considering the complexity of emotion, its various indicators, measurement, individual differences, dyadic interaction, and problems of inference.},
	author = {Cohn, Jeffrey F.},
	doi = {10.1007/978-3-540-72348-6_1},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohn - 2007 - Foundations of human computing Facial expression and emotion(2).pdf:pdf},
	isbn = {3540723463},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {Automatic facial image analysis,Emotion,Facial expression,Human-computer interaction,Measurement,Temporal dynamics},
	pages = {1--16},
	title = {{Foundations of human computing: Facial expression and emotion}},
	volume = {4451 LNAI},
	year = {2007}
}
@article{Cohen2003,
	abstract = {The most expressive way humans display emotions is through facial expressions. In this work we report on several advances we have made in building a system for classification of facial expressions from continuous video input. We introduce and test different Bayesian network classifiers for classifying expressions from video, focusing on changes in distribution assumptions, and feature dependency structures. In particular we use Naive-Bayes classifiers and change the distribution from Gaussian to Cauchy, and use Gaussian Tree-Augmented Naive Bayes (TAN) classifiers to learn the dependencies among different facial motion features. We also introduce a facial expression recognition from live video input using temporal cues. We exploit the existing methods and propose a new architecture of hidden Markov models (HMMs) for automatically segmenting and recognizing human facial expression from video sequences. The architecture performs both segmentation and recognition of the facial expressions automatically using a multi-level architecture composed of an HMM layer and a Markov model layer. We explore both person-dependent and person-independent recognition of expressions and compare the different methods. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
	author = {Cohen, Ira and Sebe, Nicu and Garg, Ashutosh and Chen, Lawrence S. and Huang, Thomas S.},
	doi = {10.1016/S1077-3142(03)00081-X},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen et al. - 2003 - Facial expression recognition from video sequences Temporal and static modeling.pdf:pdf},
	isbn = {1077-3142},
	issn = {10773142},
	journal = {Computer Vision and Image Understanding},
	number = {1-2},
	pages = {160--187},
	pmid = {8478402},
	title = {{Facial expression recognition from video sequences: Temporal and static modeling}},
	volume = {91},
	year = {2003}
}
@article{Anderson2006,
	abstract = {A fully automated, multistage system for real-time recognition of facial expression is presented. The system uses facial motion to characterize monochrome frontal views of facial expressions and is able to operate effectively in cluttered and dynamic scenes, recognizing the six emotions universally associated with unique facial expressions, namely happiness, sadness, disgust, surprise, fear, and anger. Faces are located using a spatial ratio template tracker algorithm. Optical flow of the face is subsequently determined using a real-time implementation of a robust gradient model. The expression recognition system then averages facial velocity information over identified regions of the face and cancels out rigid head motion by taking ratios of this averaged motion. The motion signatures produced are then classified using Support Vector Machines as either nonexpressive or as one of the six basic emotions. The completed system is demonstrated in two simple affective computing applications that respond in real-time to the facial expressions of the user, thereby providing the potential for improvements in the interaction between a computer user and technology.},
	author = {Anderson, Keith and McOwan, Peter W},
	doi = {10.1109/TSMCB.2005.854502},
	file = {:C$\backslash$:/Users/Andre Luiz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson, McOwan - 2006 - A real-time automated system for the recognition of human facial expressions.pdf:pdf},
	issn = {1083-4419},
	journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
	keywords = {Algorithms,Artificial Intelligence,Biometry,Biometry: methods,Computer Systems,Face,Face: anatomy {\&} histology,Facial Expression,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity},
	number = {1},
	pages = {96--105},
	pmid = {16468569},
	title = {{A real-time automated system for the recognition of human facial expressions.}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16468569},
	volume = {36},
	year = {2006}
}
@article{Monica,
	author = {Monica, Prof and Ferreira, Maria},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Reconhecimento de emo{\c{c}}{\~{o}}es atraves de Imagens em tempo real com o uso de ASM eSVM.pdf:pdf},
	title = {{Reconhecimento de emo ¸ c ˜ oes atrav ´ es de imagens em tempo real com o uso de ASM e c ˜ oes atrav ´ es de imagens em tempo real com o uso de ASM e}}
}
@article{Cesar,
	author = {Cesar, Hugo and Carneiro, De Castro and Ferreira, Paulo Fernando and Maia, Felipe},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Identifica{\c{c}}{\~{a}}o de Emo{\c{c}}{\~{o}}es a partir de express{\~{o}}es facias com redes neurais sem pesos.pdf:pdf},
	keywords = {computer vision,emotion recognition,neural network without weights,pattern recognition},
	title = {{No Title}}
}
@article{Jesus2015,
	abstract = {Desenvolver um sistema que possa reconhecer faces {\'{e}} uma tarefa complexa. Al{\'{e}}m disso, h{\'{a}} fatores externos como iluminacao inadequada e ¸ ˜ ru{\'{i}}dos nas imagens que prejudicam esse processo. Para eliminar ou amenizar os impactos destas interferˆ encias, inserir mais uma etapa no processo de reconhecimento facial pode ser uma solucao. O objetivo deste trabalho {\'{e}} avaliar e analisar os impactos que podem ser gerados pelas t{\'{e}}cnicas de Filtro Gaussiano, Filtro Bilateral e Equalizacao do Histograma, no processo de reconhecimento¸ facial atrav{\'{e}}s do Fisherfaces, em conjuntos de imagens sob condicoes desfavor{\'{a}}veis.},
	author = {Jesus, Leone and Guimar, Deivite and Pimentel, Fagner and Souza, Josemar Rodrigues De and Sim, Marco A C and Frias, Diego},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/An{\'{a}}lise de M{\'{e}}todos de Processamento de Imagens para Reconhecimento Facial utilizando Fisherfaces em Imagens sob Condi{\c{c}}{\~{o}}es Desfavor{\'{a}}veis.pdf:pdf},
	title = {{An{\'{a}}lise de M{\'{e}}todos de Processamento de Imagens para Reconhecimento Facial utilizando Fisherfaces em Imagens sob condi{\c{c}}{\~{o}}es Desfavor{\'{a}}veis}},
	url = {http://www.lbd.dcc.ufmg.br/colecoes/wticgerbase/2015/009.pdf},
	year = {2015}
}
@article{Moon1995,
	author = {Moon, Youngme and Fogg, B J and Reeves, Byron and Dryer, Chris},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/IA/p228-nass.pdf:pdf},
	journal = {Creativity},
	title = {{Be Human Personalities ?}},
	year = {1995}
}
@article{Parameswaran2007,
	abstract = {A collection of technologies termed social computing is driving a dramatic evolution of the Web, matching the dot-com era in growth, excitement, and investment. All of these share a high degree of community formation, user level content creation, and a variety of other characteristics. We provide an overview of social computing and identify salient characteristics. We argue that social computing holds tremendous disruptive potential in the business world and can significantly impact society, and outline possible changes in organized human action that could be brought about. Social computing can also have deleterious effects associated with it, including security issues. We suggest that social computing should be a priority for researchers and business leaders and illustrate the fundamental shifts in communication, computing, collaboration, and commerce brought about by this trend.},
	author = {Parameswaran, Manoj and Whinston, Andrew B},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Social Computing/Social Computing- An Overview.pdf:pdf},
	issn = {15369323},
	journal = {Communications of the Association for Information Systems},
	number = {19},
	pages = {762--780},
	title = {{Communications of the Association for Information Systems Social Computing: An Overview Social Computing: An Overview SOCIAL COMPUTING: AN OVERVIEW 1}},
	url = {http://aisel.aisnet.org/cais{\%}5Cnhttp://aisel.aisnet.org/cais},
	volume = {19},
	year = {2007}
}
@misc{Ekman1992,
	abstract = {Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion also has characteristics in common with other emotions: rapid onset, short duration, unbidden occurrence, automatic appraisal, and coherence among responses. These shared and unique characteristics are the product of our evolution, and distinguish emotions from other affective pheonomena.},
	archivePrefix = {arXiv},
	arxivId = {a},
	author = {Ekman, Paul},
	booktitle = {Cognition {\&} Emotion},
	doi = {10.1080/02699939208411068},
	eprint = {a},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Psicologia/An-Argument-For-Basic-Emotions.pdf:pdf},
	isbn = {0269-9931},
	issn = {0269-9931},
	number = {3},
	pages = {169--200},
	pmid = {665},
	title = {{An argument for basic emotions}},
	volume = {6},
	year = {1992}
}
@misc{,
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Psicologia/Facial-Sign-Of-Emotional-Experience.pdf:pdf},
	title = {{Facial-Sign-Of-Emotional-Experience}}
}
@misc{,
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Psicologia/Detec{\c{c}}{\~{a}}o de Express{\~{o}}es faciais - Umaabordagem baseada em analise do fluxo optico facial.doc:doc},
	title = {{Detec{\c{c}}{\~{a}}o de Express{\~{o}}es faciais - Umaabordagem baseada em analise do fluxo optico facial}}
}
@article{Oliveira2008,
	abstract = {Este artigo apresenta um sistema computacional que infere as emo��es raiva, medo, repulsa, surpresa, alegria e tristeza, atrav�s das express�es faciais do usu�rio captadas por uma webcam. A detec��o das emo��es est� baseada no sistema psicol�gico de codifica��o facial FACS e se utiliza de algoritmos de aprendizagem de m�quina para a sua infer�ncia. Os resultados dos experimentos mostram uma taxa de sucesso m�dia de 60{\%}, chegando a 90{\%} para as emo��es alegria e tristeza.},
	author = {Oliveira, Eduardo and Jacques, Patricia A},
	doi = {10.1145/1497470.1497488},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Psicologia/Inferindo as emo{\c{c}}{\~{o}}es do usu{\'{a}}rio pela face atrav{\'{e}}s de um sistema psicol{\'{o}}gico de codifica{\c{c}}{\~{a}}o facial.pdf:pdf},
	isbn = {9788576692034},
	journal = {IHC 2008 - Proceedings of the VIII Brazilian Symposium on Human Factors in Computing Systems},
	keywords = {FACS,Facial Expression},
	pages = {156--165},
	title = {{Inferindo as emo{\c{c}}{\~{o}}es do usu{\'{a}}rio pela face atrav{\'{e}}s de um sistema psicol{\'{o}}gico de codifica{\c{c}}{\~{a}}o facial}},
	year = {2008}
}
@article{Libralon2014,
	author = {Libralon, Giampaolo Luiz},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/teseDoutorado{\_}GiampaoloLibralon{\_}VersaoRevisada{\_}bkp.pdf:pdf},
	keywords = {Emotion recognition},
	mendeley-tags = {Emotion recognition},
	title = {{Modelagem computacional para reconhecimento de emo{\c{c}}{\~{o}}es baseada na an{\'{a}}lise facial}},
	year = {2014}
}
@article{DinizFabioAbrantes;NetoFranciscoMiltonMendes;JuniorFranciscodasChagasLima;FontesLaysaMabeldeO.;DominguesThiagodeAguiarLeal;Figueiredo2014,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {{Diniz, F{\'{a}}bio Abrantes; Neto, Francisco Milton Mendes; J{\'{u}}nior, Francisco das Chagas Lima; Fontes, Laysa Mabel de O.; Domingues, Thiago de Aguiar Leal; Figueiredo}, Lucas Silva.},
	doi = {10.1007/s13398-014-0173-7.2},
	eprint = {arXiv:1011.1669v3},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/Projeto GPG/Material Estudo/Uma Sistema de Reconhecimento de Expressoes Faciais para Apoiar um Ambiente Virtual de Aprensizagem.pdf:pdf},
	isbn = {9780874216561},
	issn = {13514180},
	journal = {Igarss 2014},
	keywords = {high resolution images,research,risks management,sustainable reconstruction},
	number = {1},
	pages = {1--5},
	pmid = {15991970},
	title = {{Um sistema de reconhecimento de express{\~{o}}es faciais para apoiar um ambiente virtual de aprendizagem}},
	url = {http://www.lbd.dcc.ufmg.br/colecoes/sbsi/2013/0042.pdf},
	volume = {0123},
	year = {2014}
}
@book{darwin1998expression,
	title={The expression of the emotions in man and animals},
	author={Darwin, Charles and Ekman, Paul and Prodger, Phillip},
	year={1998},
	publisher={Oxford University Press, USA}
}
@book{ortony1990cognitive,
	title={The cognitive structure of emotions},
	author={Ortony, Andrew and Clore, Gerald L and Collins, Allan},
	year={1990},
	publisher={Cambridge university press}
}
@article{ekman1971constants,
	title={Constants across cultures in the face and emotion.},
	author={Ekman, Paul and Friesen, Wallace V},
	journal={Journal of personality and social psychology},
	volume={17},
	number={2},
	pages={124},
	year={1971},
	publisher={American Psychological Association}
}
@article{ekman1992argument,
	title={An argument for basic emotions},
	author={Ekman, Paul},
	journal={Cognition \& emotion},
	volume={6},
	number={3-4},
	pages={169--200},
	year={1992},
	publisher={Taylor \& Francis}
}
@article{damasio1994descartes,
	title={Descartes' Error: Emotion, Reason and the Human Brain},
	author={Damasio, AR and Sutherland, Stuart},
	journal={Nature},
	volume={372},
	number={6503},
	pages={287--287},
	year={1994},
	publisher={[London: Macmillan Journals], 1869-}
}
@article{maes1994agents,
	title={Agents that reduce work and information overload},
	author={Maes, Pattie and others},
	journal={Communications of the ACM},
	volume={37},
	number={7},
	pages={30--40},
	year={1994},
	publisher={New York}
}
@article{tomkins1980affect,
	title={Affect as amplification: Some modifications in theory},
	author={Tomkins, Silvan S},
	journal={Emotion: Theory, research, and experience},
	volume={1},
	pages={141--164},
	year={1980},
	publisher={Academic Press New York}
}
@article{ekman1989argument,
	title={The argument and evidence about universals in facial expres-sions},
	author={Ekman, Paul},
	journal={Handbook of social psychophysiology},
	pages={143--164},
	year={1989},
	publisher={John Wiley Chichester, England}
}
@article{matsumoto1989american,
	title={American-Japanese cultural differences in intensity ratings of facial expressions of emotion},
	author={Matsumoto, David and Ekman, Paul},
	journal={Motivation and Emotion},
	volume={13},
	number={2},
	pages={143--157},
	year={1989},
	publisher={Springer}
}
@article{Ekman1979,
	author = {Ekman, Paul and Oster, Harriet},
	file = {:E$\backslash$:/Meus Documentos/Documentos/Faculdade/2017.1/TCC/Atigos/annurev.ps.30.020179.002523.pdf:pdf},
	title = {{FACIAL EXPRESSIONS +316 OF EMOTIONl}},
	year = {1979}
}
@book{rydfalk1987candide,
	title={CANDIDE: a parameterised face},
	author={Rydfalk, Mikael},
	year={1987},
	publisher={Link{\"o}ping Univ.}
}
@book{hjortsjo1969man,
	title={Man's face and mimic language},
	author={Hjortsj{\"o}, Carl-Herman},
	year={1969},
	publisher={Studen litteratur}
}
@article{ekman1978facial,
	title={Facial action coding system (FACS)},
	author={Ekman, Paul and Friesen, Wallace V and Hager, Joseph C},
	journal={A technique for the measurement of facial action. Consulting, Palo Alto},
	volume={22},
	year={1978}
}
@book{ekman1997face,
	title={What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)},
	author={Ekman, Paul and Rosenberg, Erika L},
	year={1997},
	publisher={Oxford University Press, USA}
}
@article{henry2012rgb,
	title={RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments},
	author={Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
	journal={The International Journal of Robotics Research},
	volume={31},
	number={5},
	pages={647--663},
	year={2012},
	publisher={SAGE Publications Sage UK: London, England}
}
@misc{kinectv2herdware,
	author = {Microsoft},
	title = {Hardware Kinect},
	year = {2013},
	howpublished = {\url{https://developer.microsoft.com/pt-br/windows/kinect/hardware}},
	note = {Acessado: 06-06-2017}
}
@misc{facstable,
	author = {Robotics Institute, CMU},
	title = {FACS - Facial Action Coding System},
	year = {2002},
	howpublished = {\url{https://www.cs.cmu.edu/~face/facs.htm}},
	note = {Acessado: 08-06-2017}
}
@misc{kinectprogramming,
	author = {Matteo Valoriani},
	title = {Programming Kinect for Windows v2},
	year = {2015},
	howpublished = {\url{https://pt.slideshare.net/MatteoValoriani/programming-with-kinect-v2?from_action=save}},
	note = {Acessado: 10-06-2017}
}
@book{russell2004inteligencia,
	title={Intelig{\^e}ncia artificial},
	author={Russell, Stuart and Norvig, Peter},
	year={2004},
	publisher={Elsevier}
}
@article{samuel1959some,
	title={Some studies in machine learning using the game of checkers},
	author={Samuel, Arthur L},
	journal={IBM Journal of research and development},
	volume={3},
	number={3},
	pages={210--229},
	year={1959},
	publisher={IBM}
}
@article{vapnik1995support,
	title={Support-vector networks},
	author={Vapnik, Vladimir and Cortes, Corinna},
	journal={Machine learning},
	volume={20},
	number={3},
	pages={273--297},
	year={1995},
	publisher={Springer}
}
@article{colonna2012abordagem,
	title={Uma abordagem para classifica{\c{c}}{\~a}o de anuros baseada em vocaliza{\c{c}}{\~o}es},
	author={Colonna, Juan Gabriel and others},
	year={2012},
	publisher={Universidade Federal do Amazonas}
}
@article{scikit-learn,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}
@article{shlens2014tutorial,
	title={A tutorial on principal component analysis},
	author={Shlens, Jonathon},
	journal={arXiv preprint arXiv:1404.1100},
	year={2014}
}
@article{sterzai2010lidar,
	title={LiDAR and hyperspectral data integration for landslide monitoring: The Test Case Of Valoria Landslide},
	author={Sterzai, Paolo and Vellico, Michela and Berti, Matteo and Coren, Franco and Corsini, Alessandro and Rosi, Alberto and Mora, Paolo and Zambonelli, Franco and Ronchetti, Francesco},
	journal={Italian Journal of Remote Sensing},
	volume={42},
	number={3},
	pages={89--99},
	year={2010}
}
@book{jolliffe2002principal,
	title={Principal component analysis},
	author={Jolliffe, Ian},
	year={2002},
	publisher={Wiley Online Library}
}
@misc{erickim2013svmkernel,
	author = {Eric Kim},
	title = {Everything You Wanted to Know about the Kernel Trick
	(But Were Too Afraid to Ask)},
	year = {2013},
	howpublished = {\url{http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html}},
	note = {Acessado: 21-06-2017}
}
@article{powers2011evaluation,
	title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
	author={Powers, David Martin},
	year={2011},
	publisher={Bioinfo Publications}
}
@article{carvalho2014digital,
	title={Digital signature of network segment for healthcare environments support},
	author={Carvalho, LF and Fernandes, G and De Assis, MVO and Rodrigues, JJPC and Proen{\c{c}}a, M Lemes},
	journal={IRBM},
	volume={35},
	number={6},
	pages={299--309},
	year={2014},
	publisher={Elsevier}
}
@inproceedings{kanade2000comprehensive,
	title={Comprehensive database for facial expression analysis},
	author={Kanade, Takeo and Cohn, Jeffrey F and Tian, Yingli},
	booktitle={Automatic Face and Gesture Recognition, 2000. Proceedings. Fourth IEEE International Conference on},
	pages={46--53},
	year={2000},
	organization={IEEE}
}
@inproceedings{lucey2010extended,
	title={The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression},
	author={Lucey, Patrick and Cohn, Jeffrey F and Kanade, Takeo and Saragih, Jason and Ambadar, Zara and Matthews, Iain},
	booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on},
	pages={94--101},
	year={2010},
	organization={IEEE}
}
@article{mase1991recognition,
	title={Recognition of facial expression from optical flow},
	author={Mase, Kenji},
	journal={IEICE transactions (E)},
	volume={74},
	pages={3474--3483},
	year={1991}
}
@book{picard1997affective,
	title={Affective computing},
	author={Picard, Rosalind W and Picard, Roalind},
	volume={252},
	year={1997},
	publisher={MIT press Cambridge}
}
@misc{kinectcandide3,
	author = {Microsoft},
	title = {Kinect Documentation, Face Tracking},
	year = {2017},
	howpublished = {\url{https://msdn.microsoft.com/en-us/library/jj130970.aspx}},
	note = {Acessado: 20-06-2017}
}
@inproceedings{dantas2015aplicaccao,
	title={Aplica{\c{c}}{\~a}o para reconhecimento din{\^a}mico de emo{\c{c}}{\~o}es em ambientes virtuais de aprendizagem},
	author={Dantas, Adilmar and de Melo, Sara and Fernandes, Marcia and Takahashi, Eduardo},
	booktitle={Anais dos Workshops do Congresso Brasileiro de Inform{\'a}tica na Educa{\c{c}}{\~a}o},
	volume={4},
	number={1},
	pages={390},
	year={2015}
}
@article{butalia2012facial,
	title={Facial expression recognition for security},
	author={Butalia, Mrs Ayesha and Ingle, Maya and Kulkarni, Parag},
	journal={International Journal of Modern Engineering Research (IJMER)},
	volume={2},
	number={4},
	pages={1449--1453},
	year={2012}
}
@inproceedings{bartlett2003real,
	title={Real Time Face Detection and Facial Expression Recognition: Development and Applications to Human Computer Interaction.},
	author={Bartlett, Marian Stewart and Littlewort, Gwen and Fasel, Ian and Movellan, Javier R},
	booktitle={Computer Vision and Pattern Recognition Workshop, 2003. CVPRW'03. Conference on},
	volume={5},
	pages={53--53},
	year={2003},
	organization={IEEE}
}
@article{yeasin2006recognition,
	title={Recognition of facial expressions and measurement of levels of interest from video},
	author={Yeasin, Mohammed and Bullot, Baptiste and Sharma, Rajeev},
	journal={IEEE Transactions on Multimedia},
	volume={8},
	number={3},
	pages={500--508},
	year={2006},
	publisher={IEEE}
}
@misc{wikifacs,
	author = {Distributed Wikipedia Mirror Project},
	title = {Facial Action Coding System},
	year = {2018},
	howpublished = {\url{https://ipfs.io/ipfs/QmXoypizjW3WknFiJnKLwHCnL72vedxjQkDDP1mXWo6uco/wiki/Facial_Action_Coding_System.html}},
	note = {Acessado: 11-05-2018}
}